{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as mlt\n",
    "import seaborn as sp\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareDatForInput():\n",
    "    def __init__(self, model_parameter):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_parameter = model_parameter\n",
    "    \n",
    "    def filter_data_by_lag_size(self, dataset, lag):\n",
    "        X_purified = []\n",
    "        for i in range(len(dataset)):\n",
    "            if (len(dataset[i]) == lag):\n",
    "                X_purified.append(dataset[i])\n",
    "        return X_purified\n",
    "    \n",
    "    def input_transform(self, real, lag, future_step = 0):\n",
    "        X_real = []\n",
    "        for i in range(len(real) - lag - future_step):\n",
    "            lag_data = []\n",
    "            for j in range(i, i+lag):\n",
    "                lag_data.append(real[j])\n",
    "            X_real.append(lag_data)\n",
    "                \n",
    "        X_real = np.stack(self.filter_data_by_lag_size(X_real, lag))\n",
    "\n",
    "        return X_real\n",
    "    \n",
    "    def train_test_split(self, X, train_ratio):\n",
    "        X_train = X[0: int(len(X) * train_ratio)]\n",
    "        X_test = X[int(len(X) * train_ratio): len(X)]\n",
    "\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def get_forecasting_ground_truth_data(self, load, window, num):\n",
    "        train_label = []\n",
    "\n",
    "        for i in range(0, len(load) - window - num):\n",
    "            lag_data = []\n",
    "            for j in range(i + window, i + window + num):\n",
    "                lag_data.append(load[j])\n",
    "            train_label.append(lag_data)\n",
    "        train_label = np.stack(train_label)\n",
    "        return train_label\n",
    "    \n",
    "    def get_train_test_dataset_forecasting(self, df, train_test_ratio):\n",
    "        real = df\n",
    "        data = self.input_transform(real, self.model_parameter.lag_window, self.model_parameter.future_step)\n",
    "        ground_truth = self.get_forecasting_ground_truth_data(real, self.model_parameter.lag_window, self.model_parameter.future_step)\n",
    "        data_train, data_test = self.train_test_split(data, train_test_ratio)\n",
    "        ground_truth_train, ground_truth_test = self.train_test_split(ground_truth, train_test_ratio)\n",
    "\n",
    "        return data_train, data_test, ground_truth_train, ground_truth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetPcaTransformedData():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def transform_data(self, df, columns):\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        df = scaler.fit_transform(df)\n",
    "        \n",
    "        self.visualize_pca_components(df)\n",
    "\n",
    "        pca = PCA(n_components=5) \n",
    "        pca.fit(df)\n",
    "\n",
    "        eigenvalues = pca.explained_variance_\n",
    "\n",
    "        # Get eigenvectors\n",
    "        eigenvectors = pca.components_\n",
    "        print(eigenvalues)\n",
    "        print(eigenvectors)\n",
    "        pca_transformed_data = pca.transform(df)\n",
    "\n",
    "        df = pd.DataFrame(df, columns=columns)\n",
    "        df_transformed = pd.DataFrame(data=pca_transformed_data, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "        df_final = pd.concat([df_transformed, df['Energy']], axis=1)\n",
    "\n",
    "        return df_final\n",
    "\n",
    "    def visualize_pca_components(self, df):\n",
    "        pca = PCA()\n",
    "        pca.fit(df)\n",
    "\n",
    "        # Pareto Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        explained_variance_ratio = pca.explained_variance_ratio_\n",
    "        cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "        plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center', label='Individual Explained Variance')\n",
    "        plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', color='r', label='Cumulative Explained Variance')\n",
    "        plt.xlabel('Principal Components')\n",
    "        plt.ylabel('Explained Variance Ratio')\n",
    "        plt.title('Pareto Plot')\n",
    "        plt.grid(True)\n",
    "        for i, txt in enumerate(np.round(explained_variance_ratio, 3)):\n",
    "            plt.annotate(txt, (i+1, explained_variance_ratio[i]), fontsize=8, ha='center', va='bottom')\n",
    "        for i, txt in enumerate(np.round(cumulative_explained_variance, 3)):\n",
    "            plt.annotate(txt, (i+1, cumulative_explained_variance[i]), fontsize=8, ha='center', va='bottom')\n",
    "        plt.legend()\n",
    "        plt.savefig('../Results/pca_analysis/pareto.png')\n",
    "        #plt.show()\n",
    "\n",
    "        # Scree Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(explained_variance_ratio) + 1), pca.explained_variance_ratio_, marker='o')\n",
    "        plt.xlabel('Principal Components')\n",
    "        plt.ylabel('Explained Variance Ratio')\n",
    "        plt.title('Scree Plot')\n",
    "        plt.grid(True)\n",
    "        for i, txt in enumerate(np.round(explained_variance_ratio, 3)):\n",
    "            plt.annotate(txt, (i+1, explained_variance_ratio[i]), fontsize=8, ha='center', va='bottom')\n",
    "        plt.savefig('../Results/pca_analysis/scree.png')\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
