{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as mlt\n",
    "import seaborn as sp\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessDataset(nn.Module):\n",
    "    def __init__(self, raw_data_file_path, dataset_type, dataset_parameters):\n",
    "        super(PreProcessDataset, self).__init__()\n",
    "        self.dataset_type = dataset_type\n",
    "        self.raw_data_file_path = raw_data_file_path\n",
    "        self.dataset_parameters = dataset_parameters\n",
    "\n",
    "    def remove_outliers(self, df):\n",
    "        column_name = 'Energy'\n",
    "        Q1 = df[column_name].quantile(0.25)\n",
    "        Q3 = df[column_name].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "            \n",
    "        # Define the lower and upper bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "        # Filter the DataFrame to keep only the non-outliers\n",
    "        df_no_outliers = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "        return df_no_outliers\n",
    "\n",
    "    def build_dataset(self, df):\n",
    "        df['Start'] =  pd.to_datetime(df['Start'])\n",
    "        df['End'] =  pd.to_datetime(df['End'])\n",
    "        return df\n",
    "\n",
    "    def resample_dataset(self, df, frequency):\n",
    "        hourly_data = []\n",
    "        for _, row in df.iterrows():\n",
    "            plugin_time = row['Start']\n",
    "            plugout_time = row['End']\n",
    "            total_energy = row['Energy']\n",
    "            if 'Charge.Duration' in df.columns:\n",
    "                total_charging_duration = row['Charge.Duration']\n",
    "            else:\n",
    "                total_charging_duration = row['Park.Duration']\n",
    "            #total_charging_duration = row['Charge.Duration']\n",
    "            enery_per_minute = total_energy / total_charging_duration\n",
    "            # Generate hourly rows\n",
    "            while plugin_time < plugout_time and total_charging_duration > 0:\n",
    "                # Round down to the nearest hour\n",
    "                start_time = plugin_time.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "                # Add one hour\n",
    "                next_start_time = start_time + timedelta(hours=1)\n",
    "\n",
    "                if next_start_time > plugout_time:\n",
    "                    break\n",
    "                    \n",
    "                time_diff = (next_start_time - plugin_time).total_seconds() / 60\n",
    "                time_diff = min(time_diff, total_charging_duration)\n",
    "                enery_consumption = time_diff * enery_per_minute\n",
    "                total_charging_duration = total_charging_duration - time_diff\n",
    "\n",
    "                hourly_data.append({\n",
    "                    'Start': start_time,\n",
    "                    'End': next_start_time,\n",
    "                    'Day': row['Day'],\n",
    "                    'Energy': enery_consumption,\n",
    "                    'Time Duration': time_diff,\n",
    "                })\n",
    "                \n",
    "                plugin_time = next_start_time\n",
    "            if total_charging_duration == 0:\n",
    "                continue\n",
    "            enery_consumption = total_charging_duration * enery_per_minute\n",
    "            hourly_data.append({\n",
    "                'Start': start_time,\n",
    "                'End': next_start_time,\n",
    "                'Day': row['Day'],\n",
    "                'Energy': enery_consumption,\n",
    "                'Time Duration': plugout_time.minute,\n",
    "            })\n",
    "\n",
    "        # Create a new DataFrame from the hourly data\n",
    "        hourly_df = pd.DataFrame(hourly_data)\n",
    "        return hourly_df\n",
    "    \n",
    "    def aggregate_dataset(self, df, frequency):\n",
    "        df = df.groupby('Start').agg({\n",
    "            'End': 'first',\n",
    "            'Day': 'first',\n",
    "            'Energy': 'sum',\n",
    "        }).reset_index()\n",
    "\n",
    "        df.set_index('Start', inplace=True)\n",
    "        df = df.resample('1H').asfreq()\n",
    "        df.reset_index(inplace=True)\n",
    "        df.loc[:,'Day'] = df['Start'].dt.dayofweek + 1\n",
    "        df = df.astype({'Day': 'int32'})\n",
    "        df['Week Day'] = (df['Day'] <= 5).astype(int)\n",
    "        df.rename(columns={'Day': 'Day of week'}, inplace=True)\n",
    "        df['Year'] = df['Start'].dt.year\n",
    "        df['Month'] = df['Start'].dt.month\n",
    "        df['Day of month'] = df['Start'].dt.day\n",
    "        df.drop(columns=['End'], inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def interpolate_data(self, df, type=None):\n",
    "        if type == None:\n",
    "            df['Energy'] = df['Energy'].replace(np.nan, 0)\n",
    "        elif type == 'linear':\n",
    "            df['Energy'] = df['Energy'].interpolate(method = type, order = 2)\n",
    "        else:\n",
    "            df['Energy'] = df['Energy'].replace(np.nan, 0)\n",
    "            df['Energy'] = df.groupby(df['Start'].dt.date)['Energy'].cumsum()\n",
    "        return df\n",
    "\n",
    "    def create_different_dataset(self, df_with_zero, dataset_type):\n",
    "        df_with_zero.to_csv('../Dataset/Processed/' + dataset_type + '_data_with_zero.csv', index=False)\n",
    "\n",
    "    def forward(self):\n",
    "        df = pd.read_csv(self.raw_data_file_path)\n",
    "    \n",
    "        df = self.remove_outliers(df)\n",
    "        df = df.loc[df['Start'] <= self.dataset_parameters.split_date]\n",
    "\n",
    "        df = self.build_dataset(df)\n",
    "        df = self.resample_dataset(df, self.dataset_parameters.resample_frequency)\n",
    "        df = self.aggregate_dataset(df, self.dataset_parameters.resample_frequency)\n",
    "\n",
    "        df_with_zero = self.interpolate_data(df.copy())\n",
    "        self.create_different_dataset(df_with_zero, self.dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
