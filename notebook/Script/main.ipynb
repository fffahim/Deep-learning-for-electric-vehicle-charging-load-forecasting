{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as mlt\n",
    "import seaborn as sns\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import json\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data_Process/data_preprocess.ipynb\n",
    "%run ../Data_Process/prepare_data.ipynb\n",
    "%run ../Models/lstm.ipynb\n",
    "%run ../Models/bi_lstm.ipynb\n",
    "%run ../Models/seq2seq.ipynb\n",
    "%run wrapper.ipynb\n",
    "%run visualize.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Config/config_data.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_palo_alto = data.palo_alto\n",
    "    parameters_jpl = data.jpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreProcessDataset(\"../Dataset/Raw/palo_alto.csv\", 'palo_alto', parameters_palo_alto)()\n",
    "PreProcessDataset(\"../Dataset/Raw/jpl.csv\", 'jpl', parameters_jpl)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum']\n",
    "\n",
    "df = pd.read_csv(\"../Dataset/Processed/palo_alto_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df.drop(columns=['Start'], inplace=True)\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.savefig('../Results/eda/correlation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Config/config_model.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_lstm = data.LSTM\n",
    "    parameters_bilstm = data.BiLSTM\n",
    "    parameters_seq2seq = data.Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepare without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum']\n",
    "\n",
    "df = pd.read_csv(\"../Dataset/Processed/palo_alto_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df.drop(columns=['Start'], inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(df, columns=columns)\n",
    "df = np.array(df)\n",
    "\n",
    "train_ratio = 0.70\n",
    "\n",
    "data_train, data_test, ground_truth_train, ground_truth_test = PrepareDatForInput(parameters_lstm).get_train_test_dataset_forecasting(df, train_ratio)\n",
    "\n",
    "step_per_epoch = len(data_train) // batch_size\n",
    "\n",
    "# Converting to tensor\n",
    "data_train = torch.from_numpy(data_train).float().to(device)\n",
    "ground_truth_train = torch.from_numpy(ground_truth_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepare with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum']\n",
    "\n",
    "df = pd.read_csv(\"../Dataset/Processed/palo_alto_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df.drop(columns=['Start'], inplace=True)\n",
    "\n",
    "pca = GetPcaTransformedData()\n",
    "pca_transformed_data = pca.transform_data(df, columns)\n",
    "df = np.array(pca_transformed_data)\n",
    "\n",
    "train_ratio = 0.70\n",
    "\n",
    "data_train, data_test, ground_truth_train, ground_truth_test = PrepareDatForInput(parameters_seq2seq).get_train_test_dataset_forecasting(df, train_ratio)\n",
    "\n",
    "step_per_epoch = len(data_train) // batch_size\n",
    "\n",
    "# Converting to tensor\n",
    "data_train = torch.from_numpy(data_train).float().to(device)\n",
    "ground_truth_train = torch.from_numpy(ground_truth_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vanilla_LSTM(parameters_lstm).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameters_lstm.learning_rate, weight_decay = 0.005)\n",
    "loss_function_lstm = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelWrapper(model_parameter=parameters_lstm, col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_lstm, gen_dataset_lstm, errors_generator_lstm = wrapper.train_model(model, optimizer, loss_function_lstm, data_train, ground_truth_train, step_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_lstm[:, -1, :].detach().cpu().numpy(), gen_dataset_lstm[:, -1, :].detach().cpu().numpy(), 000, 50000, '../Results/test1.png', 5, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % parameters_lstm.batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % parameters_lstm.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_test) // parameters_lstm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_lstm, predicted_data_lstm, loss_lstm, smape_loss, mae_loss, mse_loss, rmse_loss, r2_loss = wrapper.test_model(model, data_test, ground_truth_test, loss_function_lstm, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_lstm[:, -1, :].detach().cpu().numpy(), predicted_data_lstm[:, -1, :].detach().cpu().numpy(), 000, 500, '../Results/10_pca_lstm.png', 5, 'LSTM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bi_LSTM(parameters_bilstm).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameters_bilstm.learning_rate, weight_decay = 0.005)\n",
    "loss_function_bilstm = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelWrapper(model_parameter=parameters_bilstm, col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_bilstm, gen_dataset_bilstm, errors_generator_bilstm = wrapper.train_model(model, optimizer, loss_function_bilstm, data_train, ground_truth_train, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_bilstm[:, -1, :].detach().cpu().numpy(), gen_dataset_bilstm[:, -1, :].detach().cpu().numpy(), 000, 5000, '../Results/test1.png', 5, 'Bilstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % parameters_bilstm.batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % parameters_bilstm.batch_size)]\n",
    "\n",
    "step_per_epoch = len(data_test) // parameters_bilstm.batch_size\n",
    "\n",
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_bilstm, predicted_data_bilstm, loss_bilstm, smape_loss, mae_loss, mse_loss, rmse_loss, r2_loss = wrapper.test_model(model, data_test, ground_truth_test, loss_function_bilstm, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_bilstm[:, -1, :].detach().cpu().numpy(), predicted_data_bilstm[:, -1, :].detach().cpu().numpy(), 000, 5000, '../Results/10_pca_bilstm.png', 5, 'Bi-LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqConv1D(parameters_seq2seq).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameters_seq2seq.learning_rate, weight_decay = 0.005)\n",
    "loss_function_seq = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelWrapper(model_parameter=parameters_seq2seq, col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_seq, gen_dataset_seq, errors_generator_seq = wrapper.train_model(model, optimizer, loss_function_seq, data_train, ground_truth_train, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_seq[:, -1, :].detach().cpu().numpy(), gen_dataset_seq[:, -1, :].detach().cpu().numpy(), 000, 5000, '../Results/test1.png', 5, 'Seq2seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % parameters_seq2seq.batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % parameters_seq2seq.batch_size)]\n",
    "\n",
    "step_per_epoch = len(data_test) // parameters_seq2seq.batch_size\n",
    "\n",
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_seq, predicted_data_seq, loss_seq, smape_loss, mae_loss, mse_loss, rmse_loss, r2_loss = wrapper.test_model(model, data_test, ground_truth_test, loss_function_seq, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_seq[:, -1, :].detach().cpu().numpy(), predicted_data_seq[:, -1, :].detach().cpu().numpy(), 000, 5900, '../Results/10_pca_seq2seq.png', 5, 'Seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predicted_dataset(real_data_seq[:, -1, :].detach().cpu().numpy(), predicted_data_lstm[:, -1, :].detach().cpu().numpy(), predicted_data_bilstm[:, -1, :].detach().cpu().numpy(), predicted_data_seq[:, -1, :].detach().cpu().numpy(), 3200, 3300, '../Results/10_pca_all.png', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
